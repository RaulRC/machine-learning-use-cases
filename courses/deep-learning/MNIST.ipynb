{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos la imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker pull ermaker/keras-jupyter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos y vamos al navegador en la dirección `0.0.0.0:8888`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker run -d -p 8888:8888 \\ --name aml-deep-learning \\ \n",
    "-v /home/nanounanue/proyectos/advanced-machine-learning:/notebook \\ \n",
    "ermaker/keras.jupyter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargando y preparando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print 'X_train shape: {}'.format(X_train.shape)\n",
    "print '{} muestras de entranamiento'.format(X_train.shape[0])\n",
    "print '{} muestras de prueba'.format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print 'One hot encoding: {}'.format(Y_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(X_train[i,0], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo que vamos a construir esta basado en el tutorial: \n",
    "\n",
    "`http://eblearn.sourceforge.net/beginner_tutorial2_train.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lenet5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el se puede leer la descripción (esto tendrá más sentido conforme avancemos en la clase):\n",
    "\n",
    "```\n",
    "Let us first list out what we already know about how we want our convnet to be.\n",
    "\n",
    "    The input images are 32×32 in size with 1 channel(i.e grayscale image, not color)\n",
    "    From figure 1, we can say that there are 6-layers in our convnet.\n",
    "        Layer C1 is a convolution layer with 6 feature maps and a 5×5 kernel for each feature map.\n",
    "        Layer S1 is a subsampling layer with 6 feature maps and a 2×2 kernel for each feature map.\n",
    "        Layer C3 is a convolution layer with 16 feature maps and a 6×6 kernel for each feature map.\n",
    "        Layer S4 is a subsampling layer with 16 feature maps and a 2×2 kernel for each feature map.\n",
    "        Layer C5 is a convolution layer with 120 feature maps and a 6×6 kernel for each feature map.\n",
    "        Layer C6 is a fully connected layer\n",
    "    Let us use an additive bias and a tanh non-linearity for each layer(several other non-linearity operations can be used, like sigmoid, softmax etc.). If you do not understand why we are doing this, please look at the ConvNets section\n",
    "    Let us assuming full connections between each layer, i.e all feature maps in layer X are connected with all feature maps in layer X+1. In the next tutorial, you will see how to define more complicated connections.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(6, 5, 5, input_shape=(1, img_rows, img_cols), border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(120, 5, 5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=[\"accuracy\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epoch = 2\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size = batch_size, nb_epoch = nb_epoch,\n",
    "         verbose = 1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, show_accuracy = True, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Test score: {}'.format(score[0])\n",
    "print 'Test accuracy: {}'.format(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = model.predict_classes(X_test[:30])\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "for i in range(30):\n",
    "    plt.subplot(5, 6, i+1)\n",
    "    plt.imshow(X_test[i,0], cmap='gray')\n",
    "    plt.gca().get_xaxis().set_ticks([])\n",
    "    plt.gca().get_yaxis().set_ticks([])\n",
    "    plt.ylabel(\"Prediccion = %d\" % res[i], fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
